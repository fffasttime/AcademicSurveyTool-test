@article{amidChipyardIntegratedDesign2020,
  title = {Chipyard: {{Integrated Design}}, {{Simulation}}, and {{Implementation Framework}} for {{Custom SoCs}}},
  shorttitle = {Chipyard},
  author = {Amid, Alon and Biancolin, David and Gonzalez, Abraham and Grubb, Daniel and Karandikar, Sagar and Liew, Harrison and Magyar, Albert and Mao, Howard and Ou, Albert and Pemberton, Nathan and Rigge, Paul and Schmidt, Colin and Wright, John and Zhao, Jerry and Shao, Yakun Sophia and Asanovic, Krste and Nikolic, Borivoje},
  date = {2020-07-01},
  journaltitle = {IEEE Micro},
  shortjournal = {IEEE Micro},
  volume = {40},
  number = {4},
  pages = {10--21},
  issn = {0272-1732, 1937-4143},
  doi = {10.1109/MM.2020.2996616},
  url = {https://ieeexplore.ieee.org/document/9099108/},
  urldate = {2024-02-28},
  abstract = {Continued improvement in computing efficiency requires functional specialization of hardware designs. Agile hardware design methodologies have been proposed to alleviate the increased design costs of custom silicon architectures, but their practice thus far has been accompanied with challenges in integration and validation of complex systems-on-a-chip. We present the Chipyard framework, an integrated SoC design, simulation, and implementation environment for specialized compute systems. Chipyard includes configurable, composable, open-source, generator-based IP blocks that can be used across multiple stages of the hardware development flow while maintaining design intent and integration consistency. Through cloud-hosted FPGA-accelerated simulation and rapid ASIC implementation, Chipyard enables continuous validation of physically realizable customized systems.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\5PWGE86E\Amid 等 - 2020 - Chipyard Integrated Design, Simulation, and Imple.pdf}
}

@article{beamerCaseAcceleratingSoftware2020,
  title = {A {{Case}} for {{Accelerating Software RTL Simulation}}},
  author = {Beamer, Scott},
  date = {2020-07-01},
  journaltitle = {IEEE Micro},
  shortjournal = {IEEE Micro},
  volume = {40},
  number = {4},
  pages = {112--119},
  issn = {0272-1732, 1937-4143},
  doi = {10.1109/MM.2020.2997639},
  url = {https://ieeexplore.ieee.org/document/9099598/},
  urldate = {2024-02-28},
  abstract = {RTL simulation is a critical tool for hardware design but its current slow speed often bottlenecks the whole design process. Simulation speed becomes even more crucial for agile and open-source hardware design methodologies, because the designers not only want to iterate on designs quicker, but they may also have less resources with which to simulate them. In this article, we execute multiple simulators and analyze them with hardware performance counters. We find some open-source simulators not only outperform a leading commercial simulator, they also achieve comparable or higher instruction throughput on the host processor. Although advanced optimizations may increase the complexity of the simulator, they do not significantly hinder instruction throughput. Our findings make the case that there is significant room to accelerate software simulation and open-source simulators are a great starting point for researchers.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\T7AFPZSQ\Beamer - 2020 - A Case for Accelerating Software RTL Simulation.pdf}
}

@inproceedings{beamerEfficientlyExploitingLow2020b,
  title = {Efficiently {{Exploiting Low Activity Factors}} to {{Accelerate RTL Simulation}}},
  booktitle = {2020 57th {{ACM}}/{{IEEE Design Automation Conference}} ({{DAC}})},
  author = {Beamer, Scott and Donofrio, David},
  date = {2020-07},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{San Francisco, CA, USA}},
  doi = {10.1109/DAC18072.2020.9218632},
  url = {https://ieeexplore.ieee.org/document/9218632/},
  urldate = {2024-02-28},
  abstract = {Hardware simulation is a critical tool for design, but its slow speed often bottlenecks the entire design process. Although most signals in a digital design rarely change, most leading simulators still simulate the entirety of the design every cycle. Tracking which signals are unchanged and can thus be reused typically introduces too much overhead to deliver a practical speedup.},
  eventtitle = {2020 57th {{ACM}}/{{IEEE Design Automation Conference}} ({{DAC}})},
  isbn = {978-1-72811-085-1},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\7FEBKR7Y\\Beamer 和 Donofrio - 2020 - Efficiently Exploiting Low Activity Factors to Acc.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\HRWBWX5P\\Beamer 和 Donofrio - 2020 - Efficiently Exploiting Low Activity Factors to Acc.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\M5GILDUL\\Beamer 和 Donofrio - 2020 - Efficiently Exploiting Low Activity Factors to Acc.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\NDU3DPX3\\Beamer 和 Donofrio - 2020 - Efficiently Exploiting Low Activity Factors to Acc.pdf}
}

@article{beamerESSENTHighPerformanceRTL,
  title = {{{ESSENT}}: {{A High-Performance RTL Simulator}}},
  author = {Beamer, Scott and Nijssen, Thomas and Pandian, Krishna and Zhang, Kyle},
  abstract = {RTL simulation is a critical tool for hardware development, debugging, design space exploration, and verification. The slow speed of hardware simulation can often be a bottleneck for the design process, so any speed improvements could either reduce design times or improve design quality. We overview ESSENT, a high-performance RTL simulator available as opensource. Not only does it contain novel optimizations that make it typically faster than other software RTL simulators, the codebase can serve as a foundation for simulation research.},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\GRTPGFDZ\\Beamer 等 - ESSENT A High-Performance RTL Simulator.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\U6248KPR\\Beamer 等 - ESSENT A High-Performance RTL Simulator.pdf}
}

@inproceedings{biancolinFASEDFPGAAcceleratedSimulation2019,
  title = {{{FASED}}: {{FPGA-Accelerated Simulation}} and {{Evaluation}} of {{DRAM}}},
  shorttitle = {{{FASED}}},
  booktitle = {Proceedings of the 2019 {{ACM}}/{{SIGDA International Symposium}} on {{Field-Programmable Gate Arrays}}},
  author = {Biancolin, David and Karandikar, Sagar and Kim, Donggyu and Koenig, Jack and Waterman, Andrew and Bachrach, Jonathan and Asanovic, Krste},
  date = {2019-02-20},
  pages = {330--339},
  publisher = {{ACM}},
  location = {{Seaside CA USA}},
  doi = {10.1145/3289602.3293894},
  url = {https://dl.acm.org/doi/10.1145/3289602.3293894},
  urldate = {2024-02-28},
  abstract = {Recent work in FPGA-accelerated simulation of ASICs has shown that much of a simulator can be automatically generated from ASIC RTL. Alas, these works rely on simple models of the outer cache hierarchy and DRAM, as mapping ASIC RTL for these components into an FPGA fabric is too complex and resource intensive. To improve FPGA simulation model accuracy, we present fased, a parameterized generator of composable, high-fidelity, FPGA-hosted last-level-cache and DRAM models. fased instances are highly performant, yet they maintain timing faithfulness independently of the behavior of the host-FPGA memory system. For a given scheduling policy, a single fased instance can model nearly the entire space of realizable single-channel DDR3 memory organizations, without resynthesizing the simulator RTL. We demonstrate fased by integrating it into a flow that automatically transforms RTL for multicore RISC-V processors into full-system simulators that execute at up to 150 target MHz on cloud-hosted FPGAs.},
  eventtitle = {{{FPGA}} '19: {{The}} 2019 {{ACM}}/{{SIGDA International Symposium}} on {{Field-Programmable Gate Arrays}}},
  isbn = {978-1-4503-6137-8},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\98JT5LIT\Biancolin 等 - 2019 - FASED FPGA-Accelerated Simulation and Evaluation .pdf}
}

@article{boglioloRobustRTLPower1998,
  title = {Robust {{RTL}} Power Macromodels},
  author = {Bogliolo, A. and Benini, L.},
  date = {1998-12},
  journaltitle = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
  shortjournal = {IEEE Trans. VLSI Syst.},
  volume = {6},
  number = {4},
  pages = {578--581},
  issn = {1063-8210, 1557-9999},
  doi = {10.1109/92.736131},
  url = {http://ieeexplore.ieee.org/document/736131/},
  urldate = {2024-02-28},
  abstract = {In this paper, we propose a robust register-transfer level (RTL) power modeling methodology for functional units. Our models are consistently accurate over a wide range of input statistics, they are automatically constructed and can provide pattern-by-pattern power estimates. An additional desirable feature of our modeling methodology is the capability of accounting for the impact of technology variations, library changes and synthesis tools. Our methodology is based on the concept of node sampling, as opposed to more traditional approaches based on input sampling.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\T23XZLQD\Bogliolo 和 Benini - 1998 - Robust RTL power macromodels.pdf}
}

@inproceedings{bombieriFASTGPRTLFunctional2012,
  title = {{{FAST-GP}}: {{An RTL}} Functional Verification Framework Based on Fault Simulation on {{GP-GPUs}}},
  shorttitle = {{{FAST-GP}}},
  booktitle = {2012 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  author = {Bombieri, N. and Fummi, F. and Guarnieri, V.},
  date = {2012-03},
  pages = {562--565},
  publisher = {{IEEE}},
  location = {{Dresden}},
  doi = {10.1109/DATE.2012.6176532},
  url = {http://ieeexplore.ieee.org/document/6176532/},
  urldate = {2024-02-28},
  abstract = {This paper presents FAST-GP, a framework for functional verification of RTL designs, which is based on fault injection and parallel simulation on GP-GPUs. Given a fault model, the framework translates the RTL code into an injected C code targeting NVIDIA GPUs, thus allowing a very fast parallel automatic test pattern generation and fault simulation. The paper compares different configurations of the framework to better exploit the architectural characteristics of such GPGPUs (such as thread synchronization, branch divergence, etc.) by considering the architectural characteristics of the RTL design under verification (i.e., complexity, size, number of injected faults, etc.). Experimental results have been conducted by applying the framework to different designs, in order to prove the methodology effectiveness.},
  eventtitle = {2012 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}} 2012)},
  isbn = {978-1-4577-2145-8 978-3-9810801-8-6},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\7RD5IFJG\Bombieri 等 - 2012 - FAST-GP An RTL functional verification framework .pdf}
}

@article{bombieriFASTRTLFault2012,
  title = {{{FAST}}: {{An RTL Fault Simulation Framework}} Based on {{RTL-to-TLM Abstraction}}},
  shorttitle = {{{FAST}}},
  author = {Bombieri, Nicola and Fummi, Franco and Guarnieri, Valerio},
  date = {2012-08},
  journaltitle = {Journal of Electronic Testing},
  shortjournal = {J Electron Test},
  volume = {28},
  number = {4},
  pages = {495--510},
  issn = {0923-8174, 1573-0727},
  doi = {10.1007/s10836-012-5318-z},
  url = {http://link.springer.com/10.1007/s10836-012-5318-z},
  urldate = {2024-02-28},
  abstract = {Functional verification techniques based on fault injection and simulation at register-transfer level (RTL) have been largely investigated in the past years. Although they have various advantages such as scalability and simplicity, they commonly suffer from the low speed of the cycle-accurate RTL simulation. On the other hand, Transaction-level modeling (TLM) allows a simulation speed sensibly faster than RTL. This article presents FAST, a framework to accelerate RTL fault simulation through automatic RTL-to-TLM abstraction. FAST abstracts RTL models injected with any RTL fault model into equivalent injected TLM models thus allowing a very fast fault simulation at TLM level. The article also presents FAST-DT, a new bit-accurate data type library integrated in the framework that allows a further improvement of the simulation speed-up. Finally, the article shows how the generated TLM test patterns can be automatically synthesized into RTL test patterns by exploiting the structural information of the RTL model extracted during the abstraction process. Experimental results have been performed on several designs of different size and complexity to show the methodology effectiveness.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\UMVWJ5LZ\Bombieri 等 - 2012 - FAST An RTL Fault Simulation Framework based on R.pdf}
}

article{BuildingChipsFaster,
  title = {Building {{Chips Faster}}: {{Hardware-Compiler Co-Design}} for {{Accelerated RTL Simulation}}},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\IENJF5PQ\Building Chips Faster Hardware-Compiler Co-Design.pdf}
}

@article{caoSimuNNPreRTLInference2020,
  title = {{{SimuNN}}: {{A Pre-RTL Inference}}, {{Simulation}} and {{Evaluation Framework}} for {{Neural Networks}}},
  shorttitle = {{{SimuNN}}},
  author = {Cao, Shan and Deng, Wei and Bao, Zhenyi and Xue, Chengbo and Xu, Shugong and Zhang, Shunqing},
  date = {2020-06},
  journaltitle = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
  shortjournal = {IEEE J. Emerg. Sel. Topics Circuits Syst.},
  volume = {10},
  number = {2},
  pages = {217--230},
  issn = {2156-3357, 2156-3365},
  doi = {10.1109/JETCAS.2020.2993854},
  url = {https://ieeexplore.ieee.org/document/9091143/},
  urldate = {2024-02-28},
  abstract = {Neural networks have been widely deployed in a number of applications due to their strong learning and feature extraction ability. To meet the ever increasing accuracy requirements from various applications, neural network models have become more complicated and diversified by exploiting more layers, larger model size, and more diverse functions. As a result, the design of application specified hardware accelerators for neural networks is also becoming more difficult, especially for real-time embedded applications. To efficiently bridge the gap between algorithm and hardware design phases, a pre-RTL neural network simulator (SimuNN) is proposed in this paper to enable early phase verification and fast prototyping. SimuNN can be used for inference, simulation and also evaluation, results of which can guide the design of both neural network models and hardware accelerators. SimuNN supports inference in various data precision, and is compatible with TensorFlow, which makes it easy for platform migration. It provides multi-level trace results that can be taken as the gold model of RTL designs. Moreover, the hardware performance under various quantizations, dataflow organizations and hardware configurations can be evaluated by SimuNN based on a generalized hardware model. Based on that, two dataflow organization schemes are concluded for determining the optimal configurations of hardware architecture under various hardware and performance constraints.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\8W9HB9HA\Cao 等 - 2020 - SimuNN A Pre-RTL Inference, Simulation and Evalua.pdf}
}

@article{choiFLASHFastParallel2020,
  title = {{{FLASH}}: {{Fast}}, {{Parallel}}, and {{Accurate Simulator}} for {{HLS}}},
  shorttitle = {{{FLASH}}},
  author = {Choi, Young-Kyu and Chi, Yuze and Wang, Jie and Cong, Jason},
  date = {2020-12},
  journaltitle = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  shortjournal = {IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst.},
  volume = {39},
  number = {12},
  pages = {4828--4841},
  issn = {0278-0070, 1937-4151},
  doi = {10.1109/TCAD.2020.2970597},
  url = {https://ieeexplore.ieee.org/document/8976247/},
  urldate = {2024-02-28},
  abstract = {A large semantic gap between a high-level synthesis (HLS) design and a low-level RTL simulation environment often creates a barrier for those who are not FPGA experts. Moreover, such a low-level simulation takes a long time to complete. Software HLS simulators can help bridge this gap and accelerate the simulation process; but their shortcoming is that they do not provide performance estimation. To make matters worse, we found that the current FPGA HLS commercial software simulators sometimes produce incorrect results. In order to solve these performance estimation and correctness problems while maintaining the high speed of software simulators, this paper proposes a new HLS simulation flow named FLASH. The main idea behind the proposed flow is to extract scheduling information from the HLS tool and automatically construct an equivalent cycle-accurate simulation model while preserving C semantics. Experimental results show that FLASH runs three orders of magnitude faster than the RTL simulation.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\K8XATXNB\Choi 等 - 2020 - FLASH Fast, Parallel, and Accurate Simulator for .pdf}
}

@inproceedings{chusovConfigurableTestEnvironment2021,
  title = {Configurable {{Test Environment}} for {{RTL Simulation}} and {{Performance Evaluation}} of {{Network}} on {{Chip}} as {{Part}} of {{SoC}}},
  booktitle = {2021 {{IEEE Conference}} of {{Russian Young Researchers}} in {{Electrical}} and {{Electronic Engineering}} ({{ElConRus}})},
  author = {Chusov, Sergey A. and Primakov, Evgeniy V. and Savchenko, Yuri V. and Pereverzev, Alexey L. and Barkov, Evgeniy S.},
  date = {2021-01-26},
  pages = {1969--1974},
  publisher = {{IEEE}},
  location = {{St. Petersburg, Moscow, Russia}},
  doi = {10.1109/ElConRus51938.2021.9396634},
  url = {https://ieeexplore.ieee.org/document/9396634/},
  urldate = {2024-02-28},
  abstract = {Nowadays, the System on Chip (SoC) industry is rapidly developing. One of the objectives of SoC developers is to provide the most efficient communication between computational units. One of the possible solutions is using Networks on Chip (NoC) of various topologies with different routing algorithms. In this paper, a configurable test environment designed for cycleaccurate NoC simulation as part of a SoC, used to provide statistics about network behavior during test process, is presented. The environment is designed to evaluate NoC performance as part of a specific SoC at the development stage, when there is a full or partial RTL description of the system. The environment configuration options, its application area, general scheme and calculated NoC performance characteristics are considered. As a conclusion, an example of using the environment to evaluate the performance of a specific NoC is described in detail.},
  eventtitle = {2021 {{IEEE Conference}} of {{Russian Young Researchers}} in {{Electrical}} and {{Electronic Engineering}} ({{ElConRus}})},
  isbn = {978-1-66540-476-1},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\CBRJW3GQ\Chusov 等 - 2021 - Configurable Test Environment for RTL Simulation a.pdf}
}

@article{congFPGAHLSToday2022b,
  title = {{{FPGA HLS Today}}: {{Successes}}, {{Challenges}}, and {{Opportunities}}},
  shorttitle = {{{FPGA HLS Today}}},
  author = {Cong, Jason and Lau, Jason and Liu, Gai and Neuendorffer, Stephen and Pan, Peichen and Vissers, Kees and Zhang, Zhiru},
  date = {2022-12-31},
  journaltitle = {ACM Transactions on Reconfigurable Technology and Systems},
  shortjournal = {ACM Trans. Reconfigurable Technol. Syst.},
  volume = {15},
  number = {4},
  pages = {1--42},
  issn = {1936-7406, 1936-7414},
  doi = {10.1145/3530775},
  url = {https://dl.acm.org/doi/10.1145/3530775},
  urldate = {2024-02-28},
  abstract = {The year 2011 marked an important transition for FPGA high-level synthesis (HLS), as it went from prototyping to deployment. A decade later, in this article, we assess the progress of the deployment of HLS technology and highlight the successes in several application domains, including deep learning, video transcoding, graph processing, and genome sequencing. We also discuss the challenges faced by today’s HLS technology and the opportunities for further research and development, especially in the areas of achieving high clock frequency, coping with complex pragmas and system integration, legacy code transformation, building on open source HLS infrastructures, supporting domain-specific languages, and standardization. It is our hope that this article will inspire more research on FPGA HLS and bring it to a new height.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\8CHX6GBF\Cong 等 - 2022 - FPGA HLS Today Successes, Challenges, and Opportu.pdf}
}

@inproceedings{cornoSimulationbasedSequentialEquivalence1999,
  title = {Simulation-Based Sequential Equivalence Checking of {{RTL VHDL}}},
  booktitle = {{{ICECS}}'99. {{Proceedings}} of {{ICECS}} '99. 6th {{IEEE International Conference}} on {{Electronics}}, {{Circuits}} and {{Systems}} ({{Cat}}. {{No}}.{{99EX357}})},
  author = {Corno, F. and Reorda, M.S. and Squillero, G.},
  date = {1999},
  volume = {1},
  pages = {351--354},
  publisher = {{IEEE}},
  location = {{Pafos, Cyprus}},
  doi = {10.1109/ICECS.1999.812295},
  url = {http://ieeexplore.ieee.org/document/812295/},
  urldate = {2024-02-28},
  abstract = {This paper preserits a riovel oppraoch to eqiiivnleiice verificatioii of R T - h v e l descriptions. The propo,sed nppmach sacrifices exactiiess i n ,favor of applicability: it is /lot always able to produce 011 oizsweI; birr it is oble f a check seqiieutial eyuivalerrce of Inr-jie .systerizs. Ftirtherntore, being based 011 corimiercicil VHDL tools, if does not have arbitrary liriiitariori,s br the syntax of the descriptions.},
  eventtitle = {{{ICECS}}'99. 6th {{IEEE International Conference}} on {{Electronics}}, {{Circuits}} and {{Systems}}},
  isbn = {978-0-7803-5682-5},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\GT5W5K9P\Corno 等 - 1999 - Simulation-based sequential equivalence checking o.pdf}
}

@incollection{coussyGAUTHighLevelSynthesis2008a,
  title = {{{GAUT}}: {{A High-Level Synthesis Tool}} for {{DSP Applications}}: {{From C Algorithm}} to {{RTL Architecture}}},
  shorttitle = {{{GAUT}}},
  booktitle = {High-{{Level Synthesis}}},
  author = {Coussy, Philippe and Chavet, Cyrille and Bomel, Pierre and Heller, Dominique and Senn, Eric and Martin, Eric},
  editor = {Coussy, Philippe and Morawiec, Adam},
  date = {2008},
  pages = {147--169},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  doi = {10.1007/978-1-4020-8588-8_9},
  url = {http://link.springer.com/10.1007/978-1-4020-8588-8_9},
  urldate = {2024-02-28},
  abstract = {This chapter presents GAUT, an academic and open-source high-level synthesis tool dedicated to digital signal processing applications. Starting from an algorithmic bit-accurate specification written in C/C++, GAUT extracts the potential parallelism before processing the allocation, the scheduling and the binding tasks. Mandatory synthesis constraints are the throughput and the clock period while the memory mapping and the I/O timing diagram are optional. GAUT next generates a potentially pipelined architecture composed of a processing unit, a memory unit and a communication with a GALS/LIS interface.},
  isbn = {978-1-4020-8587-1 978-1-4020-8588-8},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\UCK63YVP\Coussy 等 - 2008 - GAUT A High-Level Synthesis Tool for DSP Applicat.pdf}
}

@inproceedings{elsabbaghAcceleratingRTLSimulation2023,
  title = {Accelerating {{RTL Simulation}} with {{Hardware-Software Co-Design}}},
  booktitle = {56th {{Annual IEEE}}/{{ACM International Symposium}} on {{Microarchitecture}}},
  author = {Elsabbagh, Fares and Sheikhha, Shabnam and Ying, Victor A. and Nguyen, Quan M. and Emer, Joel S and Sanchez, Daniel},
  date = {2023-10-28},
  pages = {153--166},
  publisher = {{ACM}},
  location = {{Toronto ON Canada}},
  doi = {10.1145/3613424.3614257},
  url = {https://dl.acm.org/doi/10.1145/3613424.3614257},
  urldate = {2024-02-28},
  abstract = {Fast simulation of digital circuits is crucial to build modern chips. But RTL (Register-Transfer-Level) simulators are slow, as they cannot exploit multicores well. Slow simulation lengthens chip design time and makes bugs more frequent. We present ASH, a parallel architecture tailored to simulation workloads. ASH consists of a tightly codesigned hardware architecture and compiler for RTL simulation. ASH exploits two key opportunities. First, it performs dataflow execution of small tasks to leverage the fine-grained parallelism in simulation workloads. Second, it performs selective event-driven execution to run only the fraction of the design exercised each cycle, skipping ineffectual tasks. ASH hardware provides a novel combination of dataflow and speculative execution, and ASH’s compiler features several novel techniques to automatically leverage this hardware.},
  eventtitle = {{{MICRO}} '23: 56th {{Annual IEEE}}/{{ACM International Symposium}} on {{Microarchitecture}}},
  isbn = {9798400703294},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\RHJ8DTZ3\Elsabbagh 等 - 2023 - Accelerating RTL Simulation with Hardware-Software.pdf}
}

@inproceedings{emamiManticoreHardwareAcceleratedRTL2023,
  title = {Manticore: {{Hardware-Accelerated RTL Simulation}} with {{Static Bulk-Synchronous Parallelism}}},
  shorttitle = {Manticore},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}}, {{Volume}} 4},
  author = {Emami, Mahyar and Kashani, Sahand and Kamahori, Keisuke and Pourghannad, Mohammad Sepehr and Raj, Ritik and Larus, James R.},
  date = {2023-03-25},
  eprint = {2301.09413},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {219--237},
  doi = {10.1145/3623278.3624750},
  url = {http://arxiv.org/abs/2301.09413},
  urldate = {2024-02-28},
  abstract = {The demise of Moore’s Law and Dennard Scaling has revived interest in specialized computer architectures and accelerators. Verification and testing of this hardware depend heavily upon cycleaccurate simulation of register-transfer-level (RTL) designs. The fastest software RTL simulators can simulate designs at 1–1000 kHz, i.e., more than three orders of magnitude slower than hardware. Improved simulators can increase designers’ productivity by speeding design iterations and permitting more exhaustive exploration. One possibility is to exploit low-level parallelism, as RTL expresses considerable fine-grain concurrency. Unfortunately, stateof-the-art RTL simulators often perform best on a single core since modern processors cannot effectively exploit fine-grain parallelism. This work presents Manticore: a parallel computer designed to accelerate RTL simulation. Manticore uses a static bulk-synchronous parallel (BSP) execution model to eliminate fine-grain synchronization overhead. It relies entirely on a compiler to schedule resources and communication, which is feasible since RTL code contains few divergent execution paths. With static scheduling, communication and synchronization no longer incur runtime overhead, making fine-grain parallelism practical. Moreover, static scheduling dramatically simplifies processor implementation, significantly increasing the number of cores that fit on a chip. Our 225-core FPGA implementation running at 475 MHz outperforms a state-of-the-art RTL simulator running on desktop and server computers in 8 out of 9 benchmarks.},
  langid = {english},
  keywords = {Computer Science - Hardware Architecture},
  file = {C:\Users\lenovo\Zotero\storage\PSB3JLWZ\Emami 等 - 2023 - Manticore Hardware-Accelerated RTL Simulation wit.pdf}
}

@inproceedings{hoeferSiFIAIFastFlexible2023a,
  title = {{{SiFI-AI}}: {{A Fast}} and {{Flexible RTL Fault Simulation Framework Tailored}} for {{AI Models}} and {{Accelerators}}},
  shorttitle = {{{SiFI-AI}}},
  booktitle = {Proceedings of the {{Great Lakes Symposium}} on {{VLSI}} 2023},
  author = {Hoefer, Julian and Kempf, Fabian and Hotfilter, Tim and Kreß, Fabian and Harbaum, Tanja and Becker, Jürgen},
  date = {2023-06-05},
  pages = {287--292},
  publisher = {{ACM}},
  location = {{Knoxville TN USA}},
  doi = {10.1145/3583781.3590226},
  url = {https://dl.acm.org/doi/10.1145/3583781.3590226},
  urldate = {2024-02-28},
  abstract = {For AI-based systems in safety-critical domains, it is inevitable to understand the impact of random hardware faults affecting the target hardware accelerators. The high degree of data reuse makes Deep Neural Network (DNN) accelerators susceptible to significant fault propagation and hence hazardous predictions. Therefore, we present SiFI-AI, a simulation framework for fault injection in DNN accelerators. SiFI-AI proposes a hybrid simulation approach combining fast AI inference with cycle-accurate RTL simulation. Time-expensive RTL simulation is only used to accurately target registers in the hardware through condition-based fault injection. This enables to reveal vulnerable DNN layers and the related fault origin. In a resilience study with 1.5 M fault injection experiments, we analyze representative DNNs and a state-of-the-art DNN accelerator to identify vulnerable layers. The study only takes 1.15 days which is 7x faster than state-of-the-art. Our experiments show the high impact of control register faults and that narrow and deep layers are 10x more resilient compared to the wide and shallow layers of a DNN.},
  eventtitle = {{{GLSVLSI}} '23: {{Great Lakes Symposium}} on {{VLSI}} 2023},
  isbn = {9798400701252},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\FJLYSCQ2\\Hoefer 等 - 2023 - SiFI-AI A Fast and Flexible RTL Fault Simulation .pdf;C\:\\Users\\lenovo\\Zotero\\storage\\ST88FXXN\\Hoefer 等 - 2023 - SiFI-AI A Fast and Flexible RTL Fault Simulation .pdf}
}

@online{hosnyCharacterizingOptimizingEDA2021,
  title = {Characterizing and {{Optimizing EDA Flows}} for the {{Cloud}}},
  author = {Hosny, Abdelrahman and Reda, Sherief},
  date = {2021-02-22},
  eprint = {2102.10800},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.10800},
  urldate = {2024-02-26},
  abstract = {Cloud computing accelerates design space exploration in logic synthesis, and parameter tuning in physical design. However, deploying EDA jobs on the cloud requires EDA teams to deeply understand the characteristics of their jobs in cloud environments. Unfortunately, there has been little to no public information on these characteristics. Thus, in this paper, we formulate the problem of migrating EDA jobs to the cloud. First, we characterize the performance of four main EDA applications, namely: synthesis, placement, routing and static timing analysis. We show that different EDA jobs require different machine configurations. Second, using observations from our characterization, we propose a novel model based on Graph Convolutional Networks to predict the total runtime of a given application on different machine configurations. Our model achieves a prediction accuracy of 87\%. Third, we develop a new formulation for optimizing cloud deployments in order to reduce deployment costs while meeting deadline constraints. We present a pseudo-polynomial optimal solution using a multichoice knapsack mapping that reduces costs by 35.29\%.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed Parallel and Cluster Computing},
  file = {C:\Users\lenovo\Zotero\storage\TY8SKT2Y\Hosny 和 Reda - 2021 - Characterizing and Optimizing EDA Flows for the Cl.pdf}
}

@inproceedings{huangGeneralpurposeParallelHeterogeneous2020,
  title = {A General-Purpose Parallel and Heterogeneous Task Programming System for {{VLSI CAD}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Computer-Aided Design}}},
  author = {Huang, Tsung-Wei},
  date = {2020-11-02},
  pages = {1--2},
  publisher = {{ACM}},
  location = {{Virtual Event USA}},
  doi = {10.1145/3400302.3415750},
  url = {https://dl.acm.org/doi/10.1145/3400302.3415750},
  urldate = {2024-02-26},
  abstract = {This paper introduces Task ow to address the critical question of “How can we make it easier to implement and deploy parallel computer-aided design (CAD) algorithms on large heterogeneous nodes with high performance and simultaneous high productivity?” Parallelizing CAD is an extremely challenging job. Modern CAD applications exhibit unique computational patterns and user requirements that need very strategic decomposition to bene t from parallelism. Task ow assists researchers and developers in the implementation complexity of parallel algorithms by introducing a new high-level programming model supported by an e cient runtime. By capitalizing on emerging parallelism comprising manycore central processing units (CPUs), graphics processing units (GPUs), and custom accelerators, Task ow enables CAD to achieve new performance and productivity milestones that were previously out of reach.},
  eventtitle = {{{ICCAD}} '20: {{IEEE}}/{{ACM International Conference}} on {{Computer-Aided Design}}},
  isbn = {978-1-4503-8026-3},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\CX6Z9ZAJ\Huang - 2020 - A general-purpose parallel and heterogeneous task .pdf}
}

@article{kimDebuggingRISCVProcessors,
  title = {Debugging {{RISC-V Processors}} with {{FPGA-Accelerated RTL Simulation}} in the {{FPGA Cloud}}},
  author = {Kim, Donggyu and Celio, Christopher and Karandikar, Sagar and Biancolin, David and Bachrach, Jonathan and Asanovic, Krste},
  abstract = {We present DESSERT, an FPGA-accelerated methodology for simulation-based RTL verification. The RTL design is automatically transformed and instrumented to allow deterministic simulation on the FPGA with initialization and state snapshot capture. Assert statements, which are present in RTL for error checking in software simulation, are automatically synthesized for quick hardware-based error checking. Print statements in the RTL design are also automatically transformed to generate logs from the FPGA, which are compared on the fly against a functional golden-model software simulator for more exhaustive error checking. To rapidly provide waveforms for debugging, two parallel deterministic FPGAaccelerated RTL simulations are run spaced apart in simulation time to support capture and replay of state snapshots immediately before an error. We demonstrate DESSERT with the public FPGA cloud services by catching bugs in a complex out-of-order processor hundreds of billions of cycles into SPEC2006int benchmarks running under Linux.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {C:\Users\lenovo\Zotero\storage\GHFZG6E2\Kim 等 - Debugging RISC-V Processors with FPGA-Accelerated .pdf}
}

@inproceedings{kimDESSERTDebuggingRTL2018,
  title = {{{DESSERT}}: {{Debugging RTL Effectively}} with {{State Snapshotting}} for {{Error Replays}} across {{Trillions}} of {{Cycles}}},
  shorttitle = {{{DESSERT}}},
  booktitle = {2018 28th {{International Conference}} on {{Field Programmable Logic}} and {{Applications}} ({{FPL}})},
  author = {Kim, Donggyu and Celio, Christopher and Karandikar, Sagar and Biancolin, David and Bachrach, Jonathan and Asanovic, Krste},
  date = {2018-08},
  pages = {76--764},
  publisher = {{IEEE}},
  location = {{Dublin, Ireland}},
  doi = {10.1109/FPL.2018.00021},
  url = {https://ieeexplore.ieee.org/document/8533471/},
  urldate = {2024-02-28},
  abstract = {We present DESSERT, an FPGA-accelerated methodology for simulation-based RTL verification. The RTL design is automatically transformed and instrumented to allow deterministic simulation on the FPGA with initialization and state snapshot capture. Assert statements, which are present in RTL for error checking in software simulation, are automatically synthesized for quick hardware-based error checking. Print statements in the RTL design are also automatically transformed to generate logs from the FPGA, which are compared on the fly against a functional golden-model software simulator for more exhaustive error checking. To rapidly provide waveforms for debugging, two parallel deterministic FPGA-accelerated RTL simulations are run spaced apart in simulation time to support capture and replay of state snapshots immediately before an error. We demonstrate DESSERT, running on public-cloud FPGAs at extremely low cost, by catching bugs in a complex out-of-order processor hundreds of billions of cycles into SPEC2006int benchmarks running under Linux.},
  eventtitle = {2018 28th {{International Conference}} on {{Field Programmable Logic}} and {{Applications}} ({{FPL}})},
  isbn = {978-1-5386-8517-4},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\8VVB2L46\Kim 等 - 2018 - DESSERT Debugging RTL Effectively with State Snap.pdf}
}

@article{kimEvaluationRISCVRTL,
  title = {Evaluation of {{RISC-V RTL}} with {{FPGA-Accelerated Simulation}}},
  author = {Kim, Donggyu and Celio, Christopher and Biancolin, David and Bachrach, Jonathan and Asanovic, Krste},
  abstract = {This paper presents a fast and accurate simulation methodology for performance, power, and energy evaluation in the hardware/software co-design flow. Cycle-level microarchitectural software simulation is the bottleneck of the hardware/software co-design cycle due to its slow speed and the difficulty of simulator validation. While sampling methodologies can ameliorate some of these challenges, we show that it is often insufficient for rigorous design evaluations. To circumvent the limitations of software simulation and sampling, we employ MIDAS, which automatically generates FPGA-accelerated simulators from RTL. These simulators are not only up to three orders-of-magnitude faster than existing microarchitectural software simulators, but also truly cycle-accurate, as the same RTL is used to build the silicon implementation. MIDAS builds on the work of Strober, namely by increasing simulator execution rate (up to tenfold) and by including an abstract L2 cache model to simulate more realistic systems without the corresponding RTL implementations. We simulated the productized, in-order processor, Rocket, and the industry-competitive, out-of-order processor, BOOM. To our knowledge, this is the first paper to present performance, power, and energy evaluations from RTL simulations running the whole SPEC2006int benchmark suite with its reference inputs.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {C:\Users\lenovo\Zotero\storage\V5LL33BV\Kim 等 - Evaluation of RISC-V RTL with FPGA-Accelerated Sim.pdf}
}

@inproceedings{kimSimmaniRuntimePower2019,
  title = {Simmani: {{Runtime Power Modeling}} for {{Arbitrary RTL}} with {{Automatic Signal Selection}}},
  shorttitle = {Simmani},
  booktitle = {Proceedings of the 52nd {{Annual IEEE}}/{{ACM International Symposium}} on {{Microarchitecture}}},
  author = {Kim, Donggyu and Zhao, Jerry and Bachrach, Jonathan and Asanović, Krste},
  date = {2019-10-12},
  pages = {1050--1062},
  publisher = {{ACM}},
  location = {{Columbus OH USA}},
  doi = {10.1145/3352460.3358322},
  url = {https://dl.acm.org/doi/10.1145/3352460.3358322},
  urldate = {2024-02-28},
  abstract = {This paper presents a novel runtime power modeling methodology which automatically identifies key signals for power dissipation of any RTL design. The toggle-pattern matrix is constructed with the VCD dumps from a training set, where each signal is represented as a high-dimensional point. By clustering signals showing similar switching activities, a small number of signals are automatically selected, and then the design-specific but workload-independent activity-based power model is constructed using regression against cycle-accurate power traces obtained from industry-standard CAD tools. We can also automatically instrument an FPGA-accelerated RTL simulation with runtime activity counters to obtain power traces of realistic workloads at speed. Our methodology is demonstrated with a heterogeneous processor composed of an in-order core and a custom vector accelerator, running not only microbenchmarks but also real-world machine-learning applications.},
  eventtitle = {{{MICRO}} '52: {{The}} 52nd {{Annual IEEE}}/{{ACM International Symposium}} on {{Microarchitecture}}},
  isbn = {978-1-4503-6938-1},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\LWCCNKRT\Kim 等 - 2019 - Simmani Runtime Power Modeling for Arbitrary RTL .pdf}
}

@inproceedings{kimStroberFastAccurate2016,
  title = {Strober: {{Fast}} and {{Accurate Sample-Based Energy Simulation}} for {{Arbitrary RTL}}},
  shorttitle = {Strober},
  booktitle = {2016 {{ACM}}/{{IEEE}} 43rd {{Annual International Symposium}} on {{Computer Architecture}} ({{ISCA}})},
  author = {Kim, Donggyu and Izraelevitz, Adam and Celio, Christopher and Kim, Hokeun and Zimmer, Brian and Lee, Yunsup and Bachrach, Jonathan and Asanovicc, Krste},
  date = {2016-06},
  pages = {128--139},
  publisher = {{IEEE}},
  location = {{Seoul, South Korea}},
  doi = {10.1109/ISCA.2016.21},
  url = {http://ieeexplore.ieee.org/document/7551388/},
  urldate = {2024-02-28},
  abstract = {This paper presents a sample-based energy simulation methodology that enables fast and accurate estimations of performance and average power for arbitrary RTL designs. Our approach uses an FPGA to simultaneously simulate the performance of an RTL design and to collect samples containing exact RTL state snapshots. Each snapshot is then replayed in gate-level simulation, resulting in a workload-specific average power estimate with confidence intervals. For arbitrary RTL and workloads, our methodology guarantees a minimum of fourorders-of-magnitude speedup over commercial CAD gate-level simulation tools and gives average energy estimates guaranteed to be within 5\% of the true average energy with 99\% confidence. We believe our open-source sample-based energy simulation tool Strober can not only rapidly provide ground truth for more abstract power models, but can enable productive design-space exploration early in the RTL design process.},
  eventtitle = {2016 {{ACM}}/{{IEEE}} 43rd {{Annual International Symposium}} on {{Computer Architecture}} ({{ISCA}})},
  isbn = {978-1-4673-8947-1},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\Q9TAUAYQ\Kim 等 - 2016 - Strober Fast and Accurate Sample-Based Energy Sim.pdf}
}

@article{kolbiSymbolicRTLSimulation,
  title = {Symbolic {{RTL}} Simulation},
  author = {Kolbi, A and Kukula, J and Damiano, R},
  abstract = {Symbolic simulation is a promising formal verification technique combining the flexibility of conventional simulation with powerful symbolic methods. Unfortunately, existing symbolic simulators are restricted to gate level simulation or handle just a synthesizable subset of an HDL. Simulation of systems composed of design, testbench and correctness checkers, however, requires the complete set of HDL constructs. We present an approach that enables symbolic simulation of the complete set of RT-level Verilog constructs with full delay support. Additionally, we propose a flexible scheme for introducing symbolic variables and demonstrate how error traces can be simulated with this new scheme. Finally, we present some experimental results on an 8051 micro-controller design which prove the effectiveness of our approach.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\P6RZ3RUR\Kolbi 等 - Symbolic RTL simulation.pdf}
}

@inproceedings{laeuferRFUZZCoveragedirectedFuzz2018,
  title = {{{RFUZZ}}: Coverage-Directed Fuzz Testing of {{RTL}} on {{FPGAs}}},
  shorttitle = {{{RFUZZ}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Computer-Aided Design}}},
  author = {Laeufer, Kevin and Koenig, Jack and Kim, Donggyu and Bachrach, Jonathan and Sen, Koushik},
  date = {2018-11-05},
  pages = {1--8},
  publisher = {{ACM}},
  location = {{San Diego California}},
  doi = {10.1145/3240765.3240842},
  url = {https://dl.acm.org/doi/10.1145/3240765.3240842},
  urldate = {2024-02-28},
  abstract = {Dynamic verification is widely used to increase confidence in the correctness of RTL circuits during the pre-silicon design phase. Despite numerous attempts over the last decades to automate the stimuli generation based on coverage feedback, Coverage Directed Test Generation (CDG) has not found the widespread adoption that one would expect. Based on new ideas from the software testing community around coverage-guided mutational fuzz testing, we propose a new approach to the CDG problem which requires minimal setup and takes advantage of FPGA-accelerated simulation for rapid testing. We provide test input and coverage definitions that allow fuzz testing to be applied to RTL circuit verification. In addition we propose and implement a series of transformation passes that make it feasible to reset arbitrary RTL designs quickly, a requirement for deterministic test execution. Alongside this paper we provide rfuzz, a fully featured implementation of our testing methodology which we make available as open-source software to the research community. An empirical evaluation of rfuzz shows promising results on archiving coverage for a wide range of different RTL designs ranging from communication IPs to an industry scale 64-bit CPU.},
  eventtitle = {{{ICCAD}} '18: {{IEEE}}/{{ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN}}},
  isbn = {978-1-4503-5950-4},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\ATK4PEJX\Laeufer 等 - 2018 - RFUZZ coverage-directed fuzz testing of RTL on FP.pdf}
}

@article{lahtiAreWeThere2019,
  title = {Are {{We There Yet}}? {{A Study}} on the {{State}} of {{High-Level Synthesis}}},
  shorttitle = {Are {{We There Yet}}?},
  author = {Lahti, Sakari and Sjovall, Panu and Vanne, Jarno and Hamalainen, Timo D.},
  date = {2019-05},
  journaltitle = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  shortjournal = {IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst.},
  volume = {38},
  number = {5},
  pages = {898--911},
  issn = {0278-0070, 1937-4151},
  doi = {10.1109/TCAD.2018.2834439},
  url = {https://ieeexplore.ieee.org/document/8356004/},
  urldate = {2024-02-28},
  abstract = {To increase productivity in designing digital hardware components, high-level synthesis (HLS) is seen as the next step in raising the design abstraction level. However, the quality of results (QoRs) of HLS tools has tended to be behind those of manual register-transfer level (RTL) flows. In this paper, we survey the scientific literature published since 2010 about the QoR and productivity differences between the HLS and RTL design flows. Altogether, our survey spans 46 papers and 118 associated applications. Our results show that on average, the QoR of RTL flow is still better than that of the state-of-the-art HLS tools. However, the average development time with HLS tools is only a third of that of the RTL flow, and a designer obtains over four times as high productivity with HLS. Based on our findings, we also present a model case study to sum up the best practices in comparative studies between HLS and RTL. The outcome of our case study is also in line with the survey results, as using an HLS tool is seen to increase the productivity by a factor of six. In addition, to help close the QoR gap, we present a survey of literature focused on improving HLS. Our results let us conclude that HLS is currently a viable option for fast prototyping and for designs with short time to market.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\4MPNJPPZ\Lahti 等 - 2019 - Are We There Yet A Study on the State of High-Lev.pdf}
}

@inproceedings{liCompilerDrivenSimulationReconfigurable2022,
  title = {Compiler-{{Driven Simulation}} of {{Reconfigurable Hardware Accelerators}}},
  booktitle = {2022 {{IEEE International Symposium}} on {{High-Performance Computer Architecture}} ({{HPCA}})},
  author = {Li, Zhijing and Ye, Yuwei and Neuendorffer, Stephen and Sampson, Adrian},
  date = {2022-04},
  pages = {619--632},
  publisher = {{IEEE}},
  location = {{Seoul, Korea, Republic of}},
  doi = {10.1109/HPCA53966.2022.00052},
  url = {https://ieeexplore.ieee.org/document/9773256/},
  urldate = {2024-02-26},
  abstract = {As customized accelerator design has become increasingly popular to keep up with the demand for high performance computing, it poses challenges for modern simulator design to adapt to such a large variety of accelerators. Existing simulators tend to two extremes: low-level and general approaches, such as RTL simulation, that can model any hardware but require substantial effort and long execution times; and higher-level application-specific models that can be much faster and easier to use but require one-off engineering effort.},
  eventtitle = {2022 {{IEEE International Symposium}} on {{High-Performance Computer Architecture}} ({{HPCA}})},
  isbn = {978-1-66542-027-3},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\94WB8C8S\Li 等 - 2022 - Compiler-Driven Simulation of Reconfigurable Hardw.pdf}
}

@inproceedings{linRTLCUDAGPU2022a,
  title = {From {{RTL}} to {{CUDA}}: {{A GPU Acceleration Flow}} for {{RTL Simulation}} with {{Batch Stimulus}}},
  shorttitle = {From {{RTL}} to {{CUDA}}},
  booktitle = {Proceedings of the 51st {{International Conference}} on {{Parallel Processing}}},
  author = {Lin, Dian-Lun and Ren, Haoxing and Zhang, Yanqing and Khailany, Brucek and Huang, Tsung-Wei},
  date = {2022-08-29},
  pages = {1--12},
  publisher = {{ACM}},
  location = {{Bordeaux France}},
  doi = {10.1145/3545008.3545091},
  url = {https://dl.acm.org/doi/10.1145/3545008.3545091},
  urldate = {2024-02-28},
  abstract = {High-throughput RTL simulation is critical for verifying today’s highly complex SoCs. Recent research has explored accelerating RTL simulation by leveraging event-driven approaches or partitioning heuristics to speed up simulation on a single stimulus. To further accelerate throughput performance, industry-quality functional verification signoff must explore running multiple stimulus (i.e., batch stimulus) simultaneously, either with directed tests or random inputs. In this paper, we propose RTLFlow, a GPU-accelerated RTL simulation flow with batch stimulus. RTLflow first transpiles RTL into CUDA kernels that each simulates a partition of the RTL simultaneously across multiple stimulus. It also leverages CUDA Graph and pipeline scheduling for efficient runtime execution. Measuring experimental results on a large industrial design (NVDLA) with 65536 stimulus, we show that RTLflow running on a single A6000 GPU can achieve a 40× runtime speed-up when compared to an 80-thread multi-core CPU baseline.},
  eventtitle = {{{ICPP}} '22: 51st {{International Conference}} on {{Parallel Processing}}},
  isbn = {978-1-4503-9733-9},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\A8HACLRX\Lin 等 - 2022 - From RTL to CUDA A GPU Acceleration Flow for RTL .pdf}
}

@inproceedings{liSymbolicSimulationEnhanced2021,
  title = {Symbolic {{Simulation Enhanced Coverage-Directed Fuzz Testing}} of {{RTL Design}}},
  booktitle = {2021 {{IEEE International Symposium}} on {{Circuits}} and {{Systems}} ({{ISCAS}})},
  author = {Li, Tun and Zou, Hongji and Luo, Dan and Qu, Wanxia},
  date = {2021-05},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Daegu, Korea}},
  doi = {10.1109/ISCAS51556.2021.9401267},
  url = {https://ieeexplore.ieee.org/document/9401267/},
  urldate = {2024-02-28},
  abstract = {With the ending of Moore’s Law and Dennard scaling, modern System-on-a-Chip (SoC) trends to incorporate a large and growing number of specialized modules for specific applications. Verification is vital to the RTL design and faces new challenges due to the growing design complexities. In this paper, we proposed a symbolic simulation enhanced coveragedirected dynamic verification technique for RTL designs. We proposed novel Full Multiplexer Toggle Coverage (FMTC) to trace and provide feedback to the verification process. The proposed method is a hybrid between symbolic simulation and mutation based fuzz testing that offsets the disadvantages of both. The achievement of high coverage is obtained by interleaved symbolic simulation and fuzz testing passes. The symbolic simulation pass is used to generate tests that direct the testing to untouched corners. While the mutation based fuzz testing pass is used to leverage test generation tasks and to enable the method to deal with large scale designs. The empirical evaluation of the method shows promising results on archiving high coverage for practical designs.},
  eventtitle = {2021 {{IEEE International Symposium}} on {{Circuits}} and {{Systems}} ({{ISCAS}})},
  isbn = {978-1-72819-201-7},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\KRK828LH\Li 等 - 2021 - Symbolic Simulation Enhanced Coverage-Directed Fuz.pdf}
}

@inproceedings{lopez-paradisFastBehaviouralRTL2023,
  title = {Fast {{Behavioural RTL Simulation}} of {{10B Transistor SoC Designs}} with {{Metro-Mpi}}},
  booktitle = {2023 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  author = {López-Paradís, Guillem and Li, Brian and Armejach, Adriá and Wallentowitz, Stefan and Moretó, Miquel and Balkind, Jonathan},
  date = {2023-04},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Antwerp, Belgium}},
  doi = {10.23919/DATE56975.2023.10137080},
  url = {https://ieeexplore.ieee.org/document/10137080/},
  urldate = {2024-02-26},
  abstract = {Chips with tens of billions of transistors have become today’s norm. These designs are straining our electronic design automation tools throughout the design process, requiring ever more computational resources. In many tools, parallelisation has improved both latency and throughput for the designer’s benefit. However, tools largely remain restricted to a single machine and in the case of RTL simulation, we believe that this leaves much potential performance on the table.},
  eventtitle = {2023 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\ZI4XV7SP\López-Paradís 等 - 2023 - Fast Behavioural RTL Simulation of 10B Transistor .pdf}
}

@inproceedings{lopez-paradisGem5RtlFramework2021,
  title = {Gem5 + Rtl: {{A Framework}} to {{Enable RTL Models Inside}} a {{Full-System Simulator}}},
  shorttitle = {Gem5 + Rtl},
  booktitle = {50th {{International Conference}} on {{Parallel Processing}}},
  author = {López-Paradís, Guillem and Armejach, Adrià and Moretó, Miquel},
  date = {2021-08-09},
  pages = {1--11},
  publisher = {{ACM}},
  location = {{Lemont IL USA}},
  doi = {10.1145/3472456.3472461},
  url = {https://dl.acm.org/doi/10.1145/3472456.3472461},
  urldate = {2024-02-28},
  abstract = {In recent years there has been a surge of interest in designing custom accelerators for power-efficient high-performance computing. However, available tools to simulate low-level RTL designs often neglect the target system in which the design will operate. This hinders proper testing and debugging of functionalities, and does not allow co-designing the accelerator to obtain a balanced and efficient architecture.},
  eventtitle = {{{ICPP}} 2021: 50th {{International Conference}} on {{Parallel Processing}}},
  isbn = {978-1-4503-9068-2},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\PHEHFYEZ\López-Paradís 等 - 2021 - gem5 + rtl A Framework to Enable RTL Models Insid.pdf}
}

@article{maALAMOFPGAAcceleration2018,
  title = {{{ALAMO}}: {{FPGA}} Acceleration of Deep Learning Algorithms with a Modularized {{RTL}} Compiler},
  shorttitle = {{{ALAMO}}},
  author = {Ma, Yufei and Suda, Naveen and Cao, Yu and Vrudhula, Sarma and Seo, Jae-sun},
  date = {2018-06},
  journaltitle = {Integration},
  shortjournal = {Integration},
  volume = {62},
  pages = {14--23},
  issn = {01679260},
  doi = {10.1016/j.vlsi.2017.12.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167926017304777},
  urldate = {2024-02-28},
  abstract = {Deploying Convolutional Neural Networks (CNNs) on a portable system is still challenging due to the large volume of data, the extensive amount of computation and frequent memory accesses. Although existing high-level synthesis tools (e.g. HLS, OpenCL) for FPGAs dramatically reduce the design time, the resulting implementations are still inefficient with respect to resource allocation for maximizing parallelism and throughput. Manual hardware-level design (i.e., RTL) can improve the efficiency and achieve greater acceleration but that requires an in-depth understanding of both the algorithm structure and the FPGA system architecture. This work presents a scalable solution that achieves the flexibility and reduced design time of high-level synthesis and the nearoptimality of an RTL implementation. The proposed solution is a compiler that analyzes the algorithm structure and parameters, and automatically integrates a set of modular and scalable computing primitives to accelerate the operation of various deep learning algorithms on an FPGA. Integrating these modules together for endto-end CNN implementations, this work quantitatively analyzes the complier's design strategy to optimize the throughput of a given CNN model under the FPGA resource constraints. The proposed RTL compiler, named ALAMO, is demonstrated on Altera Stratix-V GXA7 FPGA for the inference tasks of AlexNet and NiN CNN models, achieving 114.5 GOPS and 117.3 GOPS, respectively. This represents a 1.9X improvement in throughput when compared to the OpenCL-based design. The results illustrate the promise of the automatic compiler solution for modularized and scalable hardware acceleration of deep learning.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\JUPPN95A\Ma 等 - 2018 - ALAMO FPGA acceleration of deep learning algorith.pdf}
}

@inproceedings{mahapatraDFGPartitioningAlgorithms2018,
  title = {{{DFG Partitioning Algorithms}} for {{Coarse Grained Reconfigurable Array Assisted RTL Simulation Accelerators}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Electronics}}, {{Computing}} and {{Communication Technologies}} ({{CONECCT}})},
  author = {Mahapatra, Ipsita Biswas and Agarwal, Utkarsh and Nandy, S. K.},
  date = {2018-03},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Bangalore}},
  doi = {10.1109/CONECCT.2018.8482367},
  url = {https://ieeexplore.ieee.org/document/8482367/},
  urldate = {2024-02-28},
  abstract = {As the complexity of circuit design increases, verification of these circuits through simulation also becomes extremely challenging. This creates a bottleneck in the IC design process. Distributed simulation is one way of solving this problem where the simulation workload is distributed among the parallel processors involved in the simulation. However the design has to be carefully partitioned for this purpose. In order to perform distributed simulation, many efficient partitioning algorithms have been proposed till date. These algorithms mostly partition gate level netlist or logic circuits and reduces inter-processor communication by minimizing cutsize for a given constraint of load balance. In this paper, we present two different partitioning schemes for performing distributed simulation. They are: a Discrete Particle Swarm Optimization (DPSO) based partitioning algorithm (DPSO-PA) and an effective partitioning heuristic. These algorithms partitions Data Flow Graph (DFG) for a recently proposed Coarse Grained Reconfigurable Array assisted Hardware Accelerator (CGRA-HA). We also propose an improved version of the original DPSO methodology through careful selection of initial partition sets. It is found that the proposed heuristic based partitioning algorithm outperforms the modified DPSO-PA in terms of lesser cut-edges.},
  eventtitle = {2018 {{IEEE International Conference}} on {{Electronics}}, {{Computing}} and {{Communication Technologies}} ({{CONECCT}})},
  isbn = {978-1-5386-1112-8},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\G2UEC7V8\Mahapatra 等 - 2018 - DFG Partitioning Algorithms for Coarse Grained Rec.pdf}
}

inproceedings{mahapatraSIMAAHRTLSimulation2015,
  title = {{{SIMAAH}}: {{RTL}} Simulation Accelerator for Complex {{SoC}}'s},
  shorttitle = {{{SIMAAH}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Electronics}}, {{Computing}} and {{Communication Technologies}} ({{CONECCT}})},
  author = {Mahapatra, Ipsita Biswas and Natarajan, Santhi and {Nalesh S} and Nandy, S. K.},
  date = {2015-07},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Bangalore, India}},
  doi = {10.1109/CONECCT.2015.7383860},
  url = {http://ieeexplore.ieee.org/document/7383860/},
  urldate = {2024-02-28},
  eventtitle = {2015 {{IEEE International Conference}} on {{Electronics}}, {{Computing}} and {{Communication Technologies}} ({{CONECCT}})},
  isbn = {978-1-4799-9985-9},
  file = {C:\Users\lenovo\Zotero\storage\Y78KX5TN\Mahapatra 等 - 2015 - SIMAAH RTL simulation accelerator for complex SoC.pdf}
}

@article{maoAcceleratingLoopOrientedRTL2023,
  title = {Accelerating {{Loop-Oriented RTL Simulation With Code Instrumentation}}},
  author = {Mao, Fubing and Guo, Yapu and Liao, Xiaofei and Jin, Hai and Zhang, Wei and Liu, Haikun and Zheng, Long and Liu, Xu and Jiang, Zihan and Zheng, Xiaohua},
  date = {2023-12},
  journaltitle = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  shortjournal = {IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst.},
  volume = {42},
  number = {12},
  pages = {4985--4998},
  issn = {0278-0070, 1937-4151},
  doi = {10.1109/TCAD.2023.3276939},
  url = {https://ieeexplore.ieee.org/document/10128151/},
  urldate = {2024-02-28},
  abstract = {The hardware description of circuits usually contains many loops. Register transfer level (RTL) simulation is a critical step to verify the correctness of circuits and is time consuming. Thus, it is necessary to speed up its process. However, the speedup of existing RTL simulation acceleration techniques is usually small. Although the speedup of hardware acceleration is large, the hardware cost is high. Some methods utilize performance models without performing RTL simulation to obtain rough simulation performance and have a large speedup. However, they do not support functional verification. In order to address the problems, we propose a loop-oriented RTL simulation acceleration approach based on code instrumentation for designs synthesized by high-level synthesis. Our approach reduces the RTL simulation time by skipping a large number of repeated loop iterations, and maintains high accuracy for the prediction of the number of cycles by reserving some loop iterations. We establish a performance prediction model and an interval value formula for skipping loop iterations. We conduct experiments on the MachSuite benchmark. The results show that for the RTL simulation of single data processing and batch data processing, the average speedup of our approach can reach 7.49× and 43.3×, respectively, and the average prediction errors of the number of cycles are 1.71\% and 1.06\%, respectively. It also reveals that the interval value obtained by our approach for skipping loop iterations can quickly and effectively balance between the accuracy of prediction of the number of cycles and speedup. Compared to the state-of-the-art approach ESSENT, the speedup of our approach is better and the accuracy of prediction of the number of cycles remains at the same level as that of performance models.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\6GTFNX4Q\Mao 等 - 2023 - Accelerating Loop-Oriented RTL Simulation With Cod.pdf}
}

article{mohseniReliabilityCharacterizationActivity2019,
  title = {Reliability Characterization and Activity Analysis of {{lowRISC}} Internal Modules against Single Event Upsets Using Fault Injection and {{RTL}} Simulation},
  author = {Mohseni, Zeynab and Reviriego, Pedro},
  date = {2019-11},
  journaltitle = {Microprocessors and Microsystems},
  shortjournal = {Microprocessors and Microsystems},
  volume = {71},
  pages = {102871},
  issn = {01419331},
  doi = {10.1016/j.micpro.2019.102871},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0141933118305477},
  urldate = {2024-02-28},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\SC4IY75I\Mohseni 和 Reviriego - 2019 - Reliability characterization and activity analysis.pdf}
}

@inproceedings{mueller-gritschnederETISSMLMultilevelInstruction2018,
  title = {{{ETISS-ML}}: {{A}} Multi-Level Instruction Set Simulator with {{RTL-level}} Fault Injection Support for the Evaluation of Cross-Layer Resiliency Techniques},
  shorttitle = {{{ETISS-ML}}},
  booktitle = {2018 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  author = {Mueller-Gritschneder, Daniel and Dittrich, Martin and Weinzierl, Josef and Cheng, Eric and Mitra, Subhasish and Schlichtmann, Ulf},
  date = {2018-03},
  pages = {609--612},
  publisher = {{IEEE}},
  location = {{Dresden}},
  doi = {10.23919/DATE.2018.8342081},
  url = {https://ieeexplore.ieee.org/document/8342081/},
  urldate = {2024-02-28},
  abstract = {ETISS is an instruction set simulator (ISS) for Virtual Prototypes (VPs) modeled with SystemC/TLM. In this paper, we propose the extension ETISS-ML, which enables a multi-level simulation that switches between ISS-level and register transfer level (RTL) to accurately evaluate the impact of soft errors in the pipeline of a RISC processor. ETISS-ML achieves close-to-RTL-accurate fault injection simulation results with close-to-ISS simulation performance with a speed up gain up to 100x compared to RTL. For this, we propose an approach to dynamically determine the length of the RTL simulation period. The high simulation performance of ETISS-ML enables an ultra-efficient and accurate evaluation of cross-layer resiliency techniques for embedded applications, which requires running a large number of fault injections for long simulation scenarios. This is demonstrated on a case study of a Microcontroller Unit (MCU) executing a control algorithm for adaptive cruise control.},
  eventtitle = {2018 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  isbn = {978-3-9819263-0-9},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\WE2P5PEU\Mueller-Gritschneder 等 - 2018 - ETISS-ML A multi-level instruction set simulator .pdf}
}

inproceedings{parkMethodRTLDebugging2018,
  title = {Method of {{RTL Debugging When Using HLS}} for {{HW Design}} : {{Different Simulation Result}} of {{Verilog}} \& {{VHDL}}},
  shorttitle = {Method of {{RTL Debugging When Using HLS}} for {{HW Design}}},
  booktitle = {2018 {{International SoC Design Conference}} ({{ISOCC}})},
  author = {Park, Sang Un and Kim, Tae Pyeong and Lee, Mee Zee and Cho, Yong Beom},
  date = {2018-11},
  pages = {273--274},
  publisher = {{IEEE}},
  location = {{Daegu, Korea (South)}},
  doi = {10.1109/ISOCC.2018.8649954},
  url = {https://ieeexplore.ieee.org/document/8649954/},
  urldate = {2024-02-28},
  eventtitle = {2018 {{International SoC Design Conference}} ({{ISOCC}})},
  isbn = {978-1-5386-7960-9},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\4PW4IRT2\Park 等 - 2018 - Method of RTL Debugging When Using HLS for HW Desi.pdf}
}

@inproceedings{pintoRTLFunctionalTest2017,
  title = {{{RTL}} Functional Test Generation Using Factored Concolic Execution},
  booktitle = {2017 {{IEEE International Test Conference}} ({{ITC}})},
  author = {Pinto, Sonal and Hsiao, Michael S.},
  date = {2017-10},
  pages = {1--10},
  publisher = {{IEEE}},
  location = {{Fort Worth, TX}},
  doi = {10.1109/TEST.2017.8242038},
  url = {http://ieeexplore.ieee.org/document/8242038/},
  urldate = {2024-02-28},
  abstract = {In this paper, we present CORT, a factored concolic execution based methodology for high-level functional test generation. Our test generation effort is visualized as the systematic unraveling of the control-flow response of the design over multiple explorations. We begin by transforming the Register Transfer Level (RTL) source for the design into a high-performance C++ compiled functional simulator which is instrumented for branch coverage. An exploration begins by simulating the design with concrete stimuli. Then, we perform an interleaved cycle-by-cycle symbolic evaluation over the concrete execution trace extracted from the Control Flow Graph (CFG) of the design. The purpose of this task is to dynamically discover means to divert the control flow of the system, by mutating primary-input stimulated control statements in this trace. We record the control-flow response as a Test Decision Tree (TDT), a novel representation for the test generation effort. Successive explorations begin at system states heuristically selected from a global TDT, onto which each new decision tree resultant from an exploration is stitched. CORT succeeds at constructing functional tests for ITC99 and IWLS2005 benchmarks that achieve high branch coverage using the fewest number of input vectors, faster than existing methods. Furthermore, we achieve orders of magnitude speedup compared to previous hybrid concrete and symbolic simulation based techniques.},
  eventtitle = {2017 {{IEEE International Test Conference}} ({{ITC}})},
  isbn = {978-1-5386-3413-4},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\LED9EF4S\Pinto 和 Hsiao - 2017 - RTL functional test generation using factored conc.pdf}
}

@inproceedings{qianAcceleratingRTLSimulation2011,
  title = {Accelerating {{RTL}} Simulation with {{GPUs}}},
  booktitle = {2011 {{IEEE}}/{{ACM International Conference}} on {{Computer-Aided Design}} ({{ICCAD}})},
  author = {Qian, Hao and Deng, Yangdong},
  date = {2011-11},
  pages = {687--693},
  publisher = {{IEEE}},
  location = {{San Jose, CA, USA}},
  doi = {10.1109/ICCAD.2011.6105404},
  url = {http://ieeexplore.ieee.org/document/6105404/},
  urldate = {2024-02-28},
  abstract = {With the fast increasing complexity of integrated circuits, verification has become the bottleneck of today’s IC design flow. In fact, over 70\% of the IC design turn-around time can be spent on the verification process in a typical IC design project. Among various verification tasks, Register Transfer Level (RTL) simulation is the most widely used method to validate the correctness of digital IC designs. When simulating a large IC design with complicated internal behaviors (e.g., CPU cores running embedded software), RTL simulation can be extremely time consuming. Since RTL-to-layout is still the most prevalent IC design methodology, it is essential to speedup the RTL simulation process. Recently, General Purpose computing on Graphics Processing Units (GPGPU) is becoming a promising paradigm to accelerate computing-intensive workloads. A few recent works have demonstrated the effectiveness of using GPU to expedite gate and system level simulation tasks. In this work, we proposed an efficient GPU-accelerated RTL simulation framework. We introduce a methodology to translate Verilog RTL description into equivalent GPU source code so as to simulate circuit behavior on GPUs. In addition, a CMB based parallel simulation protocol is also adopted to provide a sufficient level of parallelism. Because RTL simulation lacks data-level parallelism, we also present a novel solution to use GPU as an efficient task-level parallel processor. Experimental results prove that our GPU based simulator outperforms a commercial sequential RTL simulator by over 20 fold.},
  eventtitle = {2011 {{IEEE}}/{{ACM International Conference}} on {{Computer-Aided Design}} ({{ICCAD}})},
  isbn = {978-1-4577-1400-9 978-1-4577-1399-6 978-1-4577-1398-9},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\4SZB7JLT\Qian 和 Deng - 2011 - Accelerating RTL simulation with GPUs.pdf}
}

@article{sanaullahSimBSPEnablingRTL,
  title = {{{SimBSP}}: {{Enabling RTL Simulation}} for {{Intel FPGA OpenCL Kernels}}},
  author = {Sanaullah, Ahmed and Yang, Chen and Crawley, Daniel and Herbordt, Martin C},
  abstract = {RTL simulation is an integral step in FPGA development since it provides cycle accurate information regarding the behavior and performance of custom architectures, without having to compile the design to actual hardware. Despite its advantages, however, RTL simulation is not currently supported by a number of commercial FPGA OpenCL toolflows, including Intel OpenCL SDK for FPGAs (IOCLF). Obtaining reliable performance values for OpenCL kernels requires a full compilation to hardware, while emulation can only provide functional verification of the C code. Thus, development and optimization time-frames for IOCLF designs can be on the order of days, even for simple applications. In this work, we present our custom Board Support Package for IOCLF, called SimBSP, which enables OpenCL kernels to be compiled for RTL simulation. Use of SimBSP reduces the time taken per OpenCL code optimization iteration from hours to minutes. We provide details regarding the standard kernel ports created by the IOCLF compiler, which can be used by testbenches to interface the generated design. We also list the addresses and descriptions of configuration registers that are used to set kernel parameters and provide a start trigger. Finally, we present details of SimBSP toolflow, which is integrated into the standard IOCLF and automates the process of generating kernel HDL and testbenches, and setting up the simulation environment. Our work on SimBSP will be made available Open Source to drive a community effort towards further improving the toolflow.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {C:\Users\lenovo\Zotero\storage\FBP9AW7H\Sanaullah 等 - SimBSP Enabling RTL Simulation for Intel FPGA Ope.pdf}
}

@online{sandalZeroShotRTLCode2024,
  title = {Zero-{{Shot RTL Code Generation}} with {{Attention Sink Augmented Large Language Models}}},
  author = {Sandal, Selim and Akturk, Ismail},
  date = {2024-01-12},
  eprint = {2401.08683},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.08683},
  urldate = {2024-02-28},
  abstract = {The design and optimization of hardware have traditionally been resource-intensive, demanding considerable expertise and dependence on established design automation tools. This paper discusses the possibility of exploiting large language models to streamline the code generation process in hardware design. In contrast to earlier studies, this paper aims to use large language models that accepts high-level design specifications through a single prompt to generate corresponding RegisterTransfer Level (RTL) code. The ability to use large language models on RTL code generation not only expedites design iteration cycles but also facilitates the exploration of design spaces that have computational challenges for conventional techniques. Through our evaluation, we demonstrate the shortcoming of existing attention mechanisms, and present the abilities of language models to produce functional, optimized, and industrystandard compliant RTL code when a novel attention mechanism is used. These findings underscore the expanding role of large language models in shaping the future landscape of architectural exploration and automation in hardware design.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Hardware Architecture,Computer Science - Machine Learning,Computer Science - Programming Languages,Computer Science - Software Engineering},
  file = {C:\Users\lenovo\Zotero\storage\4C8P76KS\Sandal 和 Akturk - 2024 - Zero-Shot RTL Code Generation with Attention Sink .pdf}
}

@article{satoArchHDLNovelHardware2018,
  title = {{{ArchHDL}}: {{A Novel Hardware RTL Modeling}} and {{High-Speed Simulation Environment}}},
  shorttitle = {{{ArchHDL}}},
  author = {Sato, Shimpei and Kobayashi, Ryohei and Kise, Kenji},
  date = {2018},
  journaltitle = {IEICE Transactions on Information and Systems},
  shortjournal = {IEICE Trans. Inf. \& Syst.},
  volume = {E101.D},
  number = {2},
  pages = {344--353},
  issn = {0916-8532, 1745-1361},
  doi = {10.1587/transinf.2017RCP0012},
  url = {https://www.jstage.jst.go.jp/article/transinf/E101.D/2/E101.D_2017RCP0012/_article},
  urldate = {2024-02-28},
  abstract = {LSIs are generally designed through four stages including architectural design, logic design, circuit design, and physical design. In architectural design and logic design, designers describe their target hardware in RTL. However, they generally use different languages for each phase. Typically a general purpose programming language such as C or C++ and a hardware description language such as Verilog HDL or VHDL are used for architectural design and logic design, respectively. That is time-consuming way for designing a hardware and more efficient design environment is required. In this paper, we propose a new hardware modeling and high-speed simulation environment for architectural design and logic design. Our environment realizes writing and verifying hardware by one language. The environment consists of (1) a new hardware description language called ArchHDL, which enables to simulate hardware faster than Verilog HDL simulation, and (2) a source code translation tool from ArchHDL code to Verilog HDL code. ArchHDL is a new language for hardware RTL modeling based on C++. The key features of this language are that (1) designers describe a combinational circuit as a function and (2) the ArchHDL library realizes non-blocking assignment in C++. Using these features, designers are able to write a hardware transparently from abstracted level description to RTL description in Verilog HDL-like style. Source codes in ArchHDL is converted to Verilog HDL codes by the translation tool and they are used to synthesize for FPGAs or ASICs. As the evaluation of our environment, we implemented a practical many-core processor in ArchHDL and measured the simulation speed on an Intel CPU and an Intel Xeon Phi processor. The simulation speed for the Intel CPU by ArchHDL achieves about 4.5 times faster than the simulation speed by Synopsys VCS. We also confirmed that the RTL simulation by ArchHDL is efficiently parallelized on the Intel Xeon Phi processor. We convert the ArchHDL code to a Verilog HDL code and estimated the hardware utilization on an FPGA. To implement a 48-node many-core processor, 71\% of entire resources of a Virtex-7 FPGA are consumed.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\ERTMI7SN\Sato 等 - 2018 - ArchHDL A Novel Hardware RTL Modeling and High-Sp.pdf}
}

@inproceedings{saxenaErrorModelEM2022,
  title = {Error {{Model}} ({{EM}})―{{A New Way}} of {{Doing Fault Simulation}}},
  booktitle = {2022 {{IEEE International Test Conference}} ({{ITC}})},
  author = {Saxena, Nirmal and Lotfi, Atieh},
  date = {2022-09},
  pages = {324--333},
  publisher = {{IEEE}},
  location = {{Anaheim, CA, USA}},
  doi = {10.1109/ITC50671.2022.00040},
  url = {https://ieeexplore.ieee.org/document/9983917/},
  urldate = {2024-02-26},
  abstract = {This paper introduces the concept of error model (EM) that replaces a traditional fault-model-based simulation. EM is a temporal simulation of fault symptoms in an application processor. This paper shows that the application resiliency metrics, such as fault coverage, derived through EM are more comprehensive and accurate than those derived through empirical models like single stuck-at faults. In addition, EM can be used on high-level simulation models (behavioral RTL, emulation or in some cases in-silicon). EM approach gives greater than three orders of performance improvement over gate netlist models using stuck-at fault simulation. This paper shows that the coverage metrics, for a billion-logic-gate GPU design, obtained through in-silicon EM closely match the corresponding coverage metrics estimated from a low-level netlist with single stuck-at fault simulation.},
  eventtitle = {2022 {{IEEE International Test Conference}} ({{ITC}})},
  isbn = {978-1-66546-270-9},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\T6PY3M5E\Saxena 和 Lotfi - 2022 - Error Model (EM)―A New Way of Doing Fault Simulati.pdf}
}

inproceedings{shaoAladdinPreRTLPowerperformance2014,
  title = {Aladdin: {{A}} Pre-{{RTL}}, Power-Performance Accelerator Simulator Enabling Large Design Space Exploration of Customized Architectures},
  shorttitle = {Aladdin},
  booktitle = {2014 {{ACM}}/{{IEEE}} 41st {{International Symposium}} on {{Computer Architecture}} ({{ISCA}})},
  author = {Shao, Yakun Sophia and Reagen, Brandon and Wei, Gu-Yeon and Brooks, David},
  date = {2014-06},
  pages = {97--108},
  publisher = {{IEEE}},
  location = {{Minneapolis, MN, USA}},
  doi = {10.1109/ISCA.2014.6853196},
  url = {http://ieeexplore.ieee.org/document/6853196/},
  urldate = {2024-02-28},
  eventtitle = {2014 {{ACM}}/{{IEEE}} 41st {{International Symposium}} on {{Computer Architecture}} ({{ISCA}})},
  isbn = {978-1-4799-4394-4 978-1-4799-4396-8},
  file = {C:\Users\lenovo\Zotero\storage\8VIBJYX9\Shao 等 - 2014 - Aladdin A pre-RTL, power-performance accelerator .pdf}
}

@inproceedings{tineTangoOptimizingCompiler2020,
  title = {Tango: {{An Optimizing Compiler}} for {{Just-In-Time RTL Simulation}}},
  shorttitle = {Tango},
  booktitle = {2020 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  author = {Tine, Blaise-Pascal and Yalamanchili, Sudhakar and Kim, Hyesoon},
  date = {2020-03},
  pages = {157--162},
  publisher = {{IEEE}},
  location = {{Grenoble, France}},
  doi = {10.23919/DATE48585.2020.9116253},
  url = {https://ieeexplore.ieee.org/document/9116253/},
  urldate = {2024-02-28},
  abstract = {With Moore’s law coming to an end, the advent of hardware specialization presents a unique challenge for a much tighter software and hardware co-design environment to exploit domain-specific optimizations and increase design efficiency. This trend is further accentuated by rapid-pace of innovations in Machine Learning and Graph Analytic, calling for a faster product development cycle for hardware accelerators and the importance of addressing the increasing cost of hardware verification. The productivity of softwarehardware co-design relies upon better integration between the software and hardware design methodologies, but more importantly in the effectiveness of the design tools and hardware simulators at reducing the development time. In this work, we developed Tango, an Optimizing compiler for Just-in-Time RTL simulation. Tango implements unique hardware-centric compiler transformations to speed up runtime code generation in a software-hardware co-design environment where hardware simulation speed is critical. Tango achieves a 6x average speedup compared to the state-of-the-art simulators.},
  eventtitle = {2020 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  isbn = {978-3-9819263-4-7},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\XJTC53R2\Tine 等 - 2020 - Tango An Optimizing Compiler for Just-In-Time RTL.pdf}
}

@article{vieiraGem5accelPreRTLSimulation2024,
  title = {Gem5-Accel: {{A Pre-RTL Simulation Toolchain}} for {{Accelerator Architecture Validation}}},
  shorttitle = {Gem5-Accel},
  author = {Vieira, João and Roma, Nuno and Falcao, Gabriel and Tomás, Pedro},
  date = {2024-01},
  journaltitle = {IEEE Computer Architecture Letters},
  shortjournal = {IEEE Comput. Arch. Lett.},
  volume = {23},
  number = {1},
  pages = {1--4},
  issn = {1556-6056, 1556-6064, 2473-2575},
  doi = {10.1109/LCA.2023.3329443},
  url = {https://ieeexplore.ieee.org/document/10304264/},
  urldate = {2024-02-28},
  abstract = {Attaining the performance and efficiency levels required by modern applications often requires the use of application-specific accelerators. However, writing synthesizable Register-Transfer Level code for such accelerators is a complex, expensive, and time-consuming process, which is cumbersome for early architecture development phases. To tackle this issue, a pre-synthesis simulation toolchain is herein proposed that facilitates the early architectural evaluation of complex accelerators aggregated to multi-level memory hierarchies. To demonstrate its usefulness, the proposed gem5-accel is used to model a tensor accelerator based on Gemmini, showing that it can successfully anticipate the results of complex hardware accelerators executing deep Neural Network models.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\YZQI6FCP\Vieira 等 - 2024 - gem5-accel A Pre-RTL Simulation Toolchain for Acc.pdf}
}

@inproceedings{wangRepCutSuperlinearParallel2023a,
  title = {{{RepCut}}: {{Superlinear Parallel RTL Simulation}} with {{Replication-Aided Partitioning}}},
  shorttitle = {{{RepCut}}},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}}, {{Volume}} 3},
  author = {Wang, Haoyuan and Beamer, Scott},
  date = {2023-03-25},
  pages = {572--585},
  publisher = {{ACM}},
  location = {{Vancouver BC Canada}},
  doi = {10.1145/3582016.3582034},
  url = {https://dl.acm.org/doi/10.1145/3582016.3582034},
  urldate = {2024-02-28},
  abstract = {Register transfer level (RTL) simulation is an invaluable tool for developing, debugging, verifying, and validating hardware designs. Despite the parallel nature of hardware, existing parallel RTL simulators yield speedups unattractive for practical application due to high communication and synchronization costs incurred by typical circuit topologies.},
  eventtitle = {{{ASPLOS}} '23: 28th {{ACM International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}}, {{Volume}} 3},
  isbn = {978-1-4503-9918-0},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\AZGN59I5\\Wang 和 Beamer - 2023 - RepCut Superlinear Parallel RTL Simulation with R.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\FNDXDV4Y\\Wang 和 Beamer - 2023 - RepCut Superlinear Parallel RTL Simulation with R.pdf}
}

@inproceedings{xingGeneralizingTandemSimulation2022,
  title = {Generalizing {{Tandem Simulation}}: {{Connecting High-level}} and {{RTL Simulation Models}}},
  shorttitle = {Generalizing {{Tandem Simulation}}},
  booktitle = {2022 27th {{Asia}} and {{South Pacific Design Automation Conference}} ({{ASP-DAC}})},
  author = {Xing, Yue and Gupta, Aarti and Malik, Sharad},
  date = {2022-01-17},
  pages = {154--159},
  publisher = {{IEEE}},
  location = {{Taipei, Taiwan}},
  doi = {10.1109/ASP-DAC52403.2022.9712564},
  url = {https://ieeexplore.ieee.org/document/9712564/},
  urldate = {2024-02-28},
  abstract = {Simulation-based testing has been the workhorse of hardware implementation validation. For processors, tandem simulation improves test and debug efficiency by cross-level simulating the Instruction Set Architecture (ISA) and RTL models, and comparing architectural-state variables at the end of each instruction rather than at the end of the whole trace. Further, the simulation may start with the ISA model and switch to the RTL model at some point by transferring the values of the architectural variables, thus speeding up the “warm-up” phase. However, thus far tandem simulation has been limited to processor designs as other SoC components lack high-level ISA models and thus the notion of instructions. Even for processors, significant manual effort is required in connecting the two models and constructing the necessary controller to synchronize/check/swap between them. This paper leverages the recently proposed Instruction-level Abstractions (ILAs) for generalizing tandem simulation to accelerators. Further, we use the refinement-map that is part of the ILA verification methodology to automate the connection between the ILA and the RTL simulation models for both processors and accelerators. We provide seven case studies to demonstrate the practical applicability of our methodology.},
  eventtitle = {2022 27th {{Asia}} and {{South Pacific Design Automation Conference}} ({{ASP-DAC}})},
  isbn = {978-1-66542-135-5},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\BK875CNG\Xing 等 - 2022 - Generalizing Tandem Simulation Connecting High-le.pdf}
}

@inproceedings{zengAccelerateLogicResimulation2021,
  title = {Accelerate {{Logic Re-simulation}} on {{GPU}} via {{Gate}}/{{Event Parallelism}} and {{State Compression}}},
  booktitle = {2021 {{IEEE}}/{{ACM International Conference On Computer Aided Design}} ({{ICCAD}})},
  author = {Zeng, Cheng and Yang, Fan and Zeng, Xuan},
  date = {2021-11-01},
  pages = {1--8},
  publisher = {{IEEE}},
  location = {{Munich, Germany}},
  doi = {10.1109/ICCAD51958.2021.9643571},
  url = {https://ieeexplore.ieee.org/document/9643571/},
  urldate = {2024-02-26},
  abstract = {In this paper, we propose a logic re-simulation method on GPU via gate/event parallelism and state compression. We achieve 2dimensional parallelism on GPU through grouping gates and splitting events. Furthermore, we compress the states to reduce the communication overhead. Asynchronous communication between GPU and CPU is used to hide the latency of dumping results. Compared with the first place of problem C of ICCAD contest 2020, the proposed method can be 47.1\% better on the speedup of single design and 10.5\% better on the geometric mean of speedup for all the benchmarks.},
  eventtitle = {2021 {{IEEE}}/{{ACM International Conference On Computer Aided Design}} ({{ICCAD}})},
  isbn = {978-1-66544-507-8},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\JCKMMUMH\Zeng 等 - 2021 - Accelerate Logic Re-simulation on GPU via GateEve.pdf}
}

@inproceedings{zengAutomaticGenerationArchitectureLevel2022,
  title = {Automatic {{Generation}} of {{Architecture-Level Models}} from {{RTL Designs}} for {{Processors}} and {{Accelerators}}},
  booktitle = {2022 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  author = {Zeng, Yu and Gupta, Aarti and Malik, Sharad},
  date = {2022-03-14},
  pages = {460--465},
  publisher = {{IEEE}},
  location = {{Antwerp, Belgium}},
  doi = {10.23919/DATE54114.2022.9774527},
  url = {https://ieeexplore.ieee.org/document/9774527/},
  urldate = {2024-02-28},
  abstract = {Hardware platforms comprise general-purpose processors and application-specific accelerators. Unlike processors, application-specific accelerators often do not have clearly specified architecture-level models/specifications (the instruction set architecture or ISA). This poses challenges to the development and verification/validation of firmware/software for these accelerators. Manually writing architecture-level models takes great effort and is error-prone. When Register-Transfer Level (RTL) designs are available, they can be a source from which to automatically derive the architecture-level models. In this work, we propose an approach for automatically generating architecture-level models for processors as well as accelerators from their RTL designs. In previous work we showed how to automatically extract the architectural state variables (ASVs) from RTL designs. (These are the state variables that are persistent across instructions.) In this work we present an algorithm for generating the update functions of the model: how the ASVs and outputs are updated by each instruction. Experiments on several processors and accelerators demonstrate that our approach can cover a wide range of hardware features and generate highquality architecture-level models within reasonable time.},
  eventtitle = {2022 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  isbn = {978-3-9819263-6-1},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\3KWNNGDM\Zeng 等 - 2022 - Automatic Generation of Architecture-Level Models .pdf}
}

@inproceedings{zhangOpportunitiesRTLGate2020a,
  title = {Opportunities for {{RTL}} and Gate Level Simulation Using {{GPUs}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Computer-Aided Design}}},
  author = {Zhang, Yanqing and Ren, Haoxing and Khailany, Brucek},
  date = {2020-11-02},
  pages = {1--5},
  publisher = {{ACM}},
  location = {{Virtual Event USA}},
  doi = {10.1145/3400302.3415773},
  url = {https://dl.acm.org/doi/10.1145/3400302.3415773},
  urldate = {2024-02-28},
  abstract = {This paper summarizes the opportunities in accelerating simulation on parallel processing hardware platforms such as GPUs. First, we give a summary of prior art. Then, we propose the idea that coding frameworks usually used for popular machine learning (ML) topics, such as PyTorch/DGL.ai, can also be used for exploring simulation purposes. We demo a crude oblivious two-value cycle gate-level simulator using the higher level ML framework APIs that exhibits {$>$}20X speedup, despite its simplistic construction. Next, we summarize recent advances in GPU features that may provide additional opportunities to further state-of-the-art results. Finally, we conclude and touch upon some potential areas for furthering research into the topic of GPU accelerated simulation.},
  eventtitle = {{{ICCAD}} '20: {{IEEE}}/{{ACM International Conference}} on {{Computer-Aided Design}}},
  isbn = {978-1-4503-8026-3},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\HAGJJ5WT\\Zhang 等 - 2020 - Opportunities for RTL and gate level simulation us.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\R8FAD7IP\\Zhang 等 - 2020 - Opportunities for RTL and gate level simulation us.pdf}
}

@article{zhaoEmpyreanALPSGTGPUaccelerated,
  title = {Empyrean {{ALPS-GT}}: {{GPU-accelerated Analog Circuit Simulation}} ({{Invited Talk}})},
  author = {Zhao, Chen and Zhou, Zhenya and Wu, Dake and Empyrean软, Zhenya Zhou},
  abstract = {SPICE (Simulation Program with Integrated Circuit Emphasis) has become an indispensable tool for the simulation of transistor-level circuits since its introduction in the early 1970s [1]. Over the years, many SPICE simulators have been introduced and their capabilities have been greatly improved. However, as we move into deeper sub-micron designs and circuit sizes keep increasing, the capabilities of current SPICE simulators prove insufficient; continuous performance breakthroughs are needed to keep up with the demands of larger circuits, high accuracy and fast turn-around. SPICE developers have put lots of effort to improve speed. In this paper, we will present how GPU is used to accelerate SPICE simulation with 10 × + performance gain.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\QP77RACP\Zhao 等 - Empyrean ALPS-GT GPU-accelerated Analog Circuit S.pdf}
}

@inproceedings{zhouKhronosFusingMemory2023,
  title = {Khronos: {{Fusing Memory Access}} for {{Improved Hardware RTL Simulation}}},
  shorttitle = {Khronos},
  booktitle = {56th {{Annual IEEE}}/{{ACM International Symposium}} on {{Microarchitecture}}},
  author = {Zhou, Kexing and Liang, Yun and Lin, Yibo and Wang, Runsheng and Huang, Ru},
  date = {2023-10-28},
  pages = {180--193},
  publisher = {{ACM}},
  location = {{Toronto ON Canada}},
  doi = {10.1145/3613424.3614301},
  url = {https://dl.acm.org/doi/10.1145/3613424.3614301},
  urldate = {2024-02-28},
  abstract = {The use of register transfer level (RTL) simulation is critical for hardware design in various aspects including verification, debugging, and design space exploration. Among various RTL simulation techniques, cycle-accurate software RTL simulation is the most prevalent approach due to its easy accessibility and high flexibility. The current state-of-the-art cycle-accurate simulators mainly use full-cycle RTL simulation that models RTL as a directed acyclic computational graph and traverses the graph in each simulation cycle. However, the adoption of full-cycle simulation makes them mainly focus on optimizing the logic evaluation within one simulation cycle, neglecting temporal optimization opportunities.},
  eventtitle = {{{MICRO}} '23: 56th {{Annual IEEE}}/{{ACM International Symposium}} on {{Microarchitecture}}},
  isbn = {9798400703294},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\3R6SJ7ZP\Zhou 等 - 2023 - Khronos Fusing Memory Access for Improved Hardwar.pdf}
}
